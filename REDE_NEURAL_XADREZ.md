# üß† Rede Neural para o Problema do Passeio do Cavalo

## üìã Vis√£o Geral

Este documento descreve a implementa√ß√£o de uma **rede neural real com backpropagation** para resolver o problema do passeio do cavalo em tabuleiros de xadrez. A rede neural aprende padr√µes de movimento atrav√©s de exemplos de jogos bem-sucedidos.

## üèóÔ∏è Arquitetura da Rede Neural

### Estrutura das Camadas

```
Entrada: 64 neur√¥nios (8x8 posi√ß√µes do tabuleiro)
    ‚Üì
Camada Oculta: 128 neur√¥nios com ativa√ß√£o sigmoid
    ‚Üì
Sa√≠da: 64 neur√¥nios (probabilidade de cada movimento)
```

### Par√¢metros da Rede

- **Entrada**: 64 dimens√µes (tabuleiro 8x8)
- **Camada Oculta**: 128 neur√¥nios
- **Sa√≠da**: 64 dimens√µes
- **Fun√ß√£o de Ativa√ß√£o**: Sigmoid
- **Inicializa√ß√£o**: Pesos pequenos aleat√≥rios (¬±0.01)

## üîß Componentes T√©cnicos

### 1. Fun√ß√£o Sigmoid

```python
def sigmoid(self, x):
    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))
```

**O que √© Sigmoid?**

- **Fun√ß√£o de ativa√ß√£o** que transforma qualquer n√∫mero em um valor entre 0 e 1
- **Formato**: S-shaped (curva em S)
- **F√≥rmula**: œÉ(x) = 1 / (1 + e^(-x))

**Por que Sigmoid?**

- **Normaliza** sa√≠das para probabilidades (0-1)
- **Suave** e diferenci√°vel (importante para backpropagation)
- **N√£o-linearidade** que permite √† rede aprender padr√µes complexos

**Exemplos de Valores:**

- sigmoid(0) = 0.5
- sigmoid(5) ‚âà 0.993
- sigmoid(-5) ‚âà 0.007

### 2. Derivada da Sigmoid

```python
def sigmoid_derivative(self, x):
    return x * (1 - x)
```

**O que √© a Derivada?**

- **Taxa de mudan√ßa** da fun√ß√£o sigmoid
- **Usada no backpropagation** para calcular gradientes
- **F√≥rmula**: œÉ'(x) = œÉ(x) √ó (1 - œÉ(x))

**Por que √© Importante?**

- **Gradiente descendente** precisa saber como ajustar pesos
- **Derivada** indica a dire√ß√£o e magnitude da mudan√ßa
- **Sem derivada**, n√£o √© poss√≠vel treinar a rede

## üéØ Representa√ß√£o dos Dados

### Vetor de Entrada (64 dimens√µes)

```python
def _position_to_input_vector(self, position):
    input_vector = np.zeros(64)  # 8x8 = 64 posi√ß√µes

    # Posi√ß√£o atual: valor 1.0
    x, y = position
    input_vector[x * 8 + y] = 1.0

    # Casas visitadas: valor 0.5
    for visited_x, visited_y in self.moves_history:
        if 0 <= visited_x < 8 and 0 <= visited_y < 8:
            input_vector[visited_x * 8 + visited_y] = 0.5

    # Movimentos poss√≠veis: valor 0.3
    for dx, dy in [(2, 1), (2, -1), (-2, 1), (-2, -1), (1, 2), (1, -2), (-1, 2), (-1, -2)]:
        new_x, new_y = x + dx, y + dy
        if 0 <= new_x < 8 and 0 <= new_y < 8 and self.board[new_x, new_y] == 0:
            input_vector[new_x * 8 + new_y] = 0.3

    return input_vector
```

**Estrutura do Vetor:**

- **Posi√ß√£o 0-63**: Representa cada casa do tabuleiro (0,0) a (7,7)
- **Valor 1.0**: Posi√ß√£o atual do cavalo
- **Valor 0.5**: Casas j√° visitadas
- **Valor 0.3**: Movimentos poss√≠veis do cavalo
- **Valor 0.0**: Casas n√£o acess√≠veis ou irrelevantes

### Vetor de Sa√≠da (64 dimens√µes)

```python
def _move_to_target_vector(self, move):
    target = np.zeros(64)
    x, y = move
    target[x * 8 + y] = 1  # Movimento correto
    return target
```

**Estrutura do Vetor Alvo:**

- **Valor 1.0**: Movimento correto (usando Warnsdorff como refer√™ncia)
- **Valor 0.0**: Todos os outros movimentos

## üöÄ Algoritmo de Treinamento

### 1. Forward Propagation

```python
def forward(self, X):
    # Camada oculta
    self.hidden = self.sigmoid(np.dot(X, self.weights1) + self.bias1)

    # Camada de sa√≠da
    self.output = self.sigmoid(np.dot(self.hidden, self.weights2) + self.bias2)

    return self.output
```

**O que Acontece:**

1. **Entrada √ó Pesos1 + Bias1** ‚Üí Camada oculta
2. **Aplica sigmoid** na camada oculta
3. **Oculta √ó Pesos2 + Bias2** ‚Üí Camada de sa√≠da
4. **Aplica sigmoid** na sa√≠da
5. **Retorna** predi√ß√£o final

### 2. Backpropagation

```python
def backward(self, X, y, learning_rate=0.01):
    m = X.shape[0]  # N√∫mero de exemplos

    # Calcula gradientes
    d_output = (self.output - y) * self.sigmoid_derivative(self.output)
    d_hidden = np.dot(d_output, self.weights2.T) * self.sigmoid_derivative(self.hidden)

    # Atualiza pesos e bias
    self.weights2 -= learning_rate * np.dot(self.hidden.T, d_output) / m
    self.bias2 -= learning_rate * np.mean(d_output, axis=0)
    self.weights1 -= learning_rate * np.dot(X.T, d_hidden) / m
    self.bias1 -= learning_rate * np.mean(d_hidden, axis=0)
```

**O que Acontece:**

1. **Calcula erro** entre predi√ß√£o e resposta correta
2. **Propaga erro** de volta pelas camadas
3. **Calcula gradientes** para cada peso
4. **Atualiza pesos** na dire√ß√£o que reduz o erro

### 3. Treinamento em Batches

```python
def train(self, X, y, epochs=100, learning_rate=0.01, batch_size=32):
    for epoch in range(epochs):
        # Shuffle dos dados
        indices = np.random.permutation(len(X))
        X_shuffled = X[indices]
        y_shuffled = y[indices]

        # Treinamento em batches
        for i in range(0, len(X), batch_size):
            batch_X = X_shuffled[i:i+batch_size]
            batch_y = y_shuffled[i:i+batch_size]

            # Forward + Backward
            self.forward(batch_X)
            self.backward(batch_X, batch_y, learning_rate)
```

**Vantagens dos Batches:**

- **Estabilidade** no treinamento
- **Efici√™ncia** computacional
- **Melhor generaliza√ß√£o**
- **Evita overfitting**

## üìä Gera√ß√£o de Dados de Treinamento

### Estrat√©gia de Treinamento

```python
def _generate_training_data(self, num_games=1000):
    training_data = []
    target_moves = []

    for game in range(num_games):
        # Reseta tabuleiro para novo jogo
        self.board = np.zeros((8, 8))
        self.moves_history = []

        # Joga usando Warnsdorff como "professor"
        start_pos = (np.random.randint(0, 8), np.random.randint(0, 8))
        # ... joga jogo completo ...

        # Adiciona dados de treinamento
        if len(self.moves_history) > 1:
            input_vector = self._position_to_input_vector(self.moves_history[-2])
            target_vector = self._move_to_target_vector(next_move)

            training_data.append(input_vector)
            target_moves.append(target_vector)
```

**Por que Warnsdorff como Professor?**

- **Algoritmo comprovado** que funciona bem
- **Gera jogos v√°lidos** e bem-sucedidos
- **Fornece exemplos de qualidade** para aprendizado
- **Base s√≥lida** para a rede neural aprender

## üéÆ Como a Rede Neural Faz Predi√ß√µes

### 1. Convers√£o de Entrada

```python
def neural_next_move(self, position):
    # Converte posi√ß√£o atual em vetor de entrada
    input_vector = self._position_to_input_vector(position)

    # Faz predi√ß√£o da rede neural
    prediction = self.neural_network.predict(input_vector)

    # Encontra melhor movimento baseado na predi√ß√£o
    best_move = None
    best_score = -float('inf')

    for move in valid_moves:
        move_score = self._calculate_move_score(move, prediction)
        if move_score > best_score:
            best_score = move_score
            best_move = move

    return best_move
```

### 2. C√°lculo de Score

```python
def _calculate_move_score(self, move, prediction):
    x, y = move

    # Score base da predi√ß√£o da rede
    base_score = prediction[x * 8 + y]

    # Bonus para movimentos que mant√™m op√ß√µes futuras
    self.board[x, y] = 1
    future_moves = len(self.get_valid_moves(move))
    self.board[x, y] = 0

    # Score composto: predi√ß√£o da rede + heur√≠stica de acessibilidade
    final_score = base_score * 0.7 + (future_moves / 8.0) * 0.3

    return final_score
```

**Score Composto:**

- **70%**: Predi√ß√£o da rede neural (aprendizado)
- **30%**: Heur√≠stica de acessibilidade (regra tradicional)

## üîç Hiperpar√¢metros e Configura√ß√µes

### Par√¢metros de Treinamento

- **√âpocas**: 100 (n√∫mero de passadas completas pelos dados)
- **Taxa de Aprendizado**: 0.01 (velocidade de ajuste dos pesos)
- **Tamanho do Batch**: 32 (exemplos processados por vez)
- **Jogos de Treinamento**: 1000 (dados de treinamento)

### Inicializa√ß√£o dos Pesos

```python
# Pesos pequenos para evitar satura√ß√£o da sigmoid
self.weights1 = np.random.randn(input_size, hidden_size) * 0.01
self.weights2 = np.random.randn(hidden_size, output_size) * 0.01

# Bias inicializado em zero
self.bias1 = np.zeros(hidden_size)
self.bias2 = np.zeros(output_size)
```

## üìà M√©tricas de Performance

### Loss Function (Fun√ß√£o de Perda)

```python
def calculate_loss(self, X, y):
    predictions = self.forward(X)
    return np.mean((predictions - y) ** 2)  # Erro quadr√°tico m√©dio
```

**Interpreta√ß√£o:**

- **Loss = 0**: Predi√ß√£o perfeita
- **Loss = 1**: Predi√ß√£o completamente errada
- **Objetivo**: Minimizar loss durante treinamento

### Hist√≥rico de Treinamento

```python
# A cada 10 √©pocas
if epoch % 10 == 0:
    loss = self.calculate_loss(X, y)
    self.training_history.append(loss)
    print(f"√âpoca {epoch}, Loss: {loss:.6f}")
```

## üöß Limita√ß√µes e Considera√ß√µes

### 1. Overfitting

- **Risco**: Rede memoriza dados de treinamento
- **Solu√ß√£o**: Valida√ß√£o cruzada, early stopping
- **Monitoramento**: Loss de valida√ß√£o vs. treinamento

### 2. Depend√™ncia dos Dados

- **Qualidade**: Depende da qualidade dos jogos de Warnsdorff
- **Quantidade**: Mais dados = melhor aprendizado
- **Variedade**: Diferentes posi√ß√µes iniciais importantes

### 3. Interpretabilidade

- **Black box**: Dif√≠cil entender por que rede escolhe movimento
- **Debugging**: Complexo de debugar decis√µes incorretas
- **Explicabilidade**: √Årea de pesquisa ativa

## üîÆ Melhorias Futuras

### 1. Arquitetura da Rede

- **Mais camadas**: Rede mais profunda
- **Dropout**: Regulariza√ß√£o para evitar overfitting
- **Batch Normalization**: Estabiliza√ß√£o do treinamento
- **Ativa√ß√µes alternativas**: ReLU, Leaky ReLU

### 2. Otimiza√ß√£o

- **Adam/SGD**: Otimizadores mais avan√ßados
- **Learning Rate Scheduling**: Taxa de aprendizado adaptativa
- **Early Stopping**: Parada autom√°tica quando overfitting
- **Cross-validation**: Valida√ß√£o mais robusta

### 3. Dados de Treinamento

- **Auto-gerados**: Rede gera seus pr√≥prios dados
- **Reinforcement Learning**: Aprende jogando contra si mesma
- **Transfer Learning**: Usa conhecimento de outros problemas
- **Data Augmentation**: Varia√ß√µes dos dados existentes

### 4. Avalia√ß√£o

- **M√©tricas m√∫ltiplas**: Acur√°cia, precis√£o, recall
- **Compara√ß√£o com heur√≠sticas**: Benchmarking
- **An√°lise de erros**: Por que rede falha
- **Visualiza√ß√£o**: Gr√°ficos de decis√£o

## üìö Refer√™ncias T√©cnicas

### Conceitos Fundamentais

- **Gradiente Descendente**: Otimiza√ß√£o de fun√ß√µes
- **Regra da Cadeia**: C√°lculo de derivadas
- **Fun√ß√µes de Ativa√ß√£o**: Sigmoid, ReLU, Tanh
- **Regulariza√ß√£o**: Dropout, L1/L2, Early Stopping

### Algoritmos Relacionados

- **Q-Learning**: Aprendizado por refor√ßo
- **Genetic Algorithms**: Otimiza√ß√£o evolutiva
- **Monte Carlo Tree Search**: Explora√ß√£o de √°rvores
- **AlphaZero**: Combina√ß√£o de RL e redes neurais

## üéØ Conclus√£o

A implementa√ß√£o da rede neural para o problema do passeio do cavalo representa uma abordagem **h√≠brida** que combina:

1. **Aprendizado autom√°tico** atrav√©s de backpropagation
2. **Heur√≠sticas tradicionais** como base de conhecimento
3. **Representa√ß√£o estruturada** do problema do xadrez
4. **Treinamento supervisionado** com dados de qualidade

Esta implementa√ß√£o serve como **base s√≥lida** para experimentos futuros e demonstra como **redes neurais cl√°ssicas** podem ser aplicadas a problemas de **otimiza√ß√£o combinat√≥ria**.

---

_Documento criado para facilitar compreens√£o e melhorias futuras da implementa√ß√£o da rede neural para o problema do passeio do cavalo._
